import pandas as pd
import os

# === 1Ô∏è‚É£ Paths ===
DATA_PATH = r"C:\Users\Chetana\OneDrive\Desktop\SCM\DATA"
CLEANED_PATH = os.path.join(DATA_PATH, "cleaned_data")
os.makedirs(CLEANED_PATH, exist_ok=True)

INPUT_FILE = os.path.join(DATA_PATH, "Port_locations.csv")  # Change if needed
OUTPUT_FILE = os.path.join(CLEANED_PATH, "cleaned_port_locations.csv")
PARQUET_FILE = os.path.join(CLEANED_PATH, "cleaned_port_locations.parquet")

print(f"üìÇ Loading {INPUT_FILE}")
df = pd.read_csv(INPUT_FILE)

print(f"‚úÖ Loaded shape: {df.shape}")
print(f"üìù Columns: {list(df.columns)}")

# === 2Ô∏è‚É£ Clean & Deduplicate ===
# Remove leading/trailing whitespace
df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

# Convert country and port_name to proper case (first letter capital)
df["country"] = df["country"].str.title()
df["port_name"] = df["port_name"].str.title()

# Drop exact duplicates
before = len(df)
df = df.drop_duplicates()
after = len(df)
print(f"üßπ Removed {before - after} duplicate rows")

# === 3Ô∏è‚É£ Save Cleaned Data ===
df.to_csv(OUTPUT_FILE, index=False)
df.to_parquet(PARQUET_FILE, index=False)

print(f"‚úÖ Cleaned Port Locations data saved: {OUTPUT_FILE}")
print(f"üì¶ Parquet file saved: {PARQUET_FILE}")
print(f"üî¢ Final rows: {len(df)}, Columns: {len(df.columns)}")
print(df.head(10))
